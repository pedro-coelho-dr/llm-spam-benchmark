# Benchmark de LLMs para DetecÃ§Ã£o de Spam em SMS

## Dataset

O experimento utiliza o conjunto de dados **SMS Spam Collection v.1**, disponÃ­vel no repositÃ³rio da UCI Machine Learning Repository:

https://archive.ics.uci.edu/dataset/228/sms+spam+collection

**DescriÃ§Ã£o tÃ©cnica:**  
O dataset contÃ©m 5.574 mensagens em inglÃªs, rotuladas como `ham` (legÃ­timas) ou `spam`.  
O formato original Ã© um arquivo texto tabulado (TSV), com duas colunas: `label` e `text`.

**DistribuiÃ§Ã£o:**  
- Ham: 4.827 mensagens (â‰ˆ 86,6%)  
- Spam: 747 mensagens (â‰ˆ 13,4%)  

**Autores:** Tiago A. Almeida e JosÃ© MarÃ­a GÃ³mez Hidalgo (2013).

## Papers

**ReferÃªncias**

- [ALMEIDA, Tiago A.; GÃ“MEZ HIDALGO, JosÃ© MarÃ­a; SILVA, Tiago P. (2013) â€” *Towards SMS Spam Filtering: Results under a New Dataset.*](papers/2013-Almeida-Towards_SMS_Spam_Filtering_UCI_Dataset.pdf.pdf)
- [SHIRANI MEHR, Hamed; SHAMS, Saeed. (2013) â€” *SMS Spam Detection Using Machine Learning.*](papers/2013-ShiraniMehr-SMS_Spam_Detection_Using_Machine_Learning.pdf.pdf)
- [ILYASA, Sinar Nadhif; KHADIDOS, Alaa Omar. (2024) â€” *Optimized SMS Spam Detection Using SVM-DistilBERT and Voting Classifier: A Comparative Study on the Impact of Lemmatization.*](papers/2024-IlyasaKhadidos-Optimized_SMS_Spam_Detection_SVM_DistilBERT.pdf)
## PrÃ©-processamento

O script `src/preprocess.py` realiza a limpeza e estruturaÃ§Ã£o do dataset original para uso em experimentos com LLMs.

**Etapas:**  
1. Leitura do arquivo `data/raw` (formato TSV, sem cabeÃ§alho).  
2. AtribuiÃ§Ã£o de um identificador Ãºnico (`id`) a cada mensagem.  
3. NormalizaÃ§Ãµes aplicadas:  
   - DecodificaÃ§Ã£o de entidades HTML (`&lt;` â†’ `<`, `&gt;` â†’ `>`)  
   - NormalizaÃ§Ã£o Unicode (NFKC)  
   - Colapso de espaÃ§os e quebras de linha  
4. RemoÃ§Ã£o de linhas duplicadas e nulas.  
5. GeraÃ§Ã£o de saÃ­das:  
   - `data/smsspam_dataset.csv` â†’ dataset completo (`id,label,text`)  
   - `data/smsspam_shuffled.csv` â†’ versÃ£o embaralhada, sem rÃ³tulos (`id,text`)  
   - `data/dataset_info.md` â†’ resumo estatÃ­stico

**DecisÃµes de design:**  
- O texto foi mantido com capitalizaÃ§Ã£o, pontuaÃ§Ã£o e sÃ­mbolos originais.  
- Nenhuma lematizaÃ§Ã£o, remoÃ§Ã£o de stopwords ou stemming foi aplicada.  
- O objetivo Ã© preservar o contexto e o tom das mensagens, relevantes para inferÃªncia em LLMs.

## Modelos Utilizados

- gpt-5  
- gpt-5-mini  
- gpt-5-nano  
- gpt-4.1  
- gpt-4.1-mini  
- gpt-4o  
- gpt-4o-mini  
- gpt-3.5-turbo
  
## System Prompt

Define a instruÃ§Ã£o fixa do modelo. O prompt especifica a tarefa de classificaÃ§Ã£o e exige apenas o rÃ³tulo como saÃ­da:

```
"You are a binary text classifier for SMS messages. "
"Classify each message as exactly one of the following labels:\n"
"- ham: legitimate, personal, or non-promotional content\n"
"- spam: promotional, fraudulent, or unsolicited content\n\n"
"Respond with only the label â€” 'ham' or 'spam' â€” without explanation or punctuation."
```

## CriaÃ§Ã£o dos Batches

### `create_all_batches.py`
Gera um arquivo `.jsonl` por modelo em `data/batches/`.  
Cada linha contÃ©m uma requisiÃ§Ã£o para a API no formato:

```json
{
  "custom_id": "123",
  "method": "POST",
  "url": "/v1/chat/completions",
  "body": {
    "model": "gpt-4o",
    "messages": [
      {"role": "system", "content": "<SYSTEM_PROMPT>"},
      {"role": "user", "content": "Free entry in 2 a weekly competition..."}
    ]
  }
}
```

### `create_batch_input.py`
VersÃ£o simplificada para gerar um Ãºnico batch (modelo padrÃ£o `gpt-3.5-turbo`).

SaÃ­da:  
```
data/batches/
 â”œâ”€â”€ batch_input_gpt-5.jsonl
 â”œâ”€â”€ batch_input_gpt-4o-mini.jsonl
 â””â”€â”€ ...
```



## SubmissÃ£o dos Batches

### `submit_batch_single.py`
Envia um batch especÃ­fico:
1. Faz upload do arquivo `.jsonl` para a API.  
2. Cria um job batch com tempo mÃ¡ximo de 24h.  
3. Retorna o `batch_id` para monitoramento.

### `run_all_batches.py`
Itera sobre todos os arquivos em `data/batches/` e envia cada um sequencialmente.  
Usa `extract_model_name()` para identificar o modelo pelo nome do arquivo.  
Armazena logs e trata exceÃ§Ãµes de falha no envio.


## Download e Parsing dos Resultados

### `parse_batch_output.py`
ApÃ³s a conclusÃ£o de um batch:
1. Faz download do arquivo de saÃ­da (`.jsonl`).  
2. LÃª cada linha, extrai `id` e `prediction`.  
3. Gera `results/<model>/predictions.csv`.

### `parse_multiple_batches.py`
Processa vÃ¡rios `batch_id` listados em um arquivo texto.  
Baixa, identifica o modelo e converte as respostas para CSV de forma automÃ¡tica.


## Estrutura de SaÃ­da

ApÃ³s o processamento completo:

```
data/
 â”œâ”€â”€ smsspam_shuffled.csv
 â””â”€â”€ batches/
      â”œâ”€â”€ batch_input_gpt-4o.jsonl
      â”œâ”€â”€ batch_input_gpt-4o-mini.jsonl
      â””â”€â”€ ...
results/
 â”œâ”€â”€ gpt-4o/
 â”‚    â”œâ”€â”€ batch_output.jsonl
 â”‚    â””â”€â”€ predictions.csv
 â”œâ”€â”€ gpt-5-mini/
 â”‚    â”œâ”€â”€ batch_output.jsonl
 â”‚    â””â”€â”€ predictions.csv
 â””â”€â”€ ...
```

## ðŸ“Š Resultados 

### Notebook
[evaluate_models.ipynb](notebooks/evaluate_models.ipynb)

### Imagens

**ComparaÃ§Ã£o entre Modelos**  
![comparacao](img/comparacao.png)

**Falsos Positivos e Negativos**  
![fpfn](img/fpfn.png)

**Matriz de ConfusÃ£o**  
![matriz](img/matriz.png)

**Trade-off PrecisÃ£o vs Recall**  
![tradeoff](img/tradeoff.png)

**TriÃ¢ngulo de Performance**  
![triangle](img/triangle.png)


